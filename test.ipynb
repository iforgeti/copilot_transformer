{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "emb_dim = 300                \n",
    "hid_dim = 1024              \n",
    "num_layers = 3               \n",
    "dropout_rate = 0.45 \n",
    "\n",
    "\n",
    "param ={\"emb_dim\":emb_dim ,\"hid_dim\":hid_dim ,\"num_layers\":num_layers,\"dropout_rate\" :dropout_rate}\n",
    "\n",
    "torch.save(param,\"param.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param = torch.load(\"vocab.pt\")\n",
    "\n",
    "print(param)\n",
    "\n",
    "print(param[\"vocab_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def sasa():<br><br>       n=0<br>       return n\n"
     ]
    }
   ],
   "source": [
    "original_str = \"def sasa():\\n\\n       n=0\\n       return n\"\n",
    "modified_str = original_str.replace('\\n', '<br>')\n",
    "print(modified_str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 52229, 'emb_dim': 150, 'hid_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.4}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "params_path = \"model/params.pt\"\n",
    "params = torch.load(params_path)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 54996, 'emb_dim': 150, 'hid_dim': 1024, 'num_layers': 2, 'dropout_rate': 0.4}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params['vocab_size'] = 54996\n",
    "print(params)\n",
    "torch.save(params,params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "emb_dim = 150               # 400 in the paper\n",
    "hid_dim = 1024                # 1150 in the paper\n",
    "num_layers = 2                # 3 in the paper\n",
    "dropout_rate = 0.4              \n",
    "lr = 1e-3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdssdf sadf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"asdssdf sadf    \".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"model/code-search-net-tokenizer-mod\")\n",
    "\n",
    "params_path = \"model/param.pt\"\n",
    "\n",
    "OUTPUT_DIM = tokenizer.vocab_size + len(tokenizer.all_special_tokens)\n",
    "\n",
    "HID_DIM = 256\n",
    "\n",
    "DEC_LAYERS = 3\n",
    "\n",
    "DEC_HEADS = 8\n",
    "\n",
    "DEC_PF_DIM = 512\n",
    "\n",
    "DEC_DROPOUT = 0.37\n",
    "\n",
    "TRG_PAD_IDX = tokenizer.pad_token_id\n",
    "\n",
    "params = {\"OUTPUT_DIM\":OUTPUT_DIM,\"HID_DIM\":HID_DIM ,\"DEC_LAYERS\":DEC_LAYERS,\"DEC_HEADS\":DEC_HEADS ,\"DEC_PF_DIM\":DEC_PF_DIM,\"DEC_DROPOUT\" :DEC_DROPOUT, \"TRG_PAD_IDX\":TRG_PAD_IDX}\n",
    "torch.save(params,params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.models_architect import Decoder\n",
    "\n",
    "save_path = \"model/best_Decoder.pt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = Decoder( params[\"OUTPUT_DIM\"], params[\"HID_DIM\"],params[\"DEC_LAYERS\"], params[\"DEC_HEADS\"],\n",
    "                params[\"DEC_PF_DIM\"], params[\"DEC_DROPOUT\"], device, params[\"TRG_PAD_IDX\"])\n",
    "\n",
    "model.load_state_dict(torch.load(save_path))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (pos_emb): Embedding(130, 256)\n",
       "  (trg_emb): Embedding(32772, 256)\n",
       "  (dropout): Dropout(p=0.37, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0): DecoderLayer(\n",
       "      (norm_att): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_maskedatt): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_masked): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (ff): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.37, inplace=False)\n",
       "    )\n",
       "    (1): DecoderLayer(\n",
       "      (norm_att): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_maskedatt): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_masked): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (ff): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.37, inplace=False)\n",
       "    )\n",
       "    (2): DecoderLayer(\n",
       "      (norm_att): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm_maskedatt): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (multi_masked): MultiHeadAttentionLayer(\n",
       "        (fc_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (fc): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (ff): PositionwiseFeedforwardLayer(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (dropout): Dropout(p=0.37, inplace=False)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.37, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=32772, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg_text =\"import matplotlib.pyplot as\"\n",
    "tokenized =tokenizer(trg_text)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg =torch.LongTensor([tokenizer.bos_token_id]+tokenized).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[32770,   646,  8027,    14, 13563,   465]]), torch.Size([1, 6]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg,trg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trg=trg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-12.3374,  -1.1788,   2.0753,  ..., -12.3273, -12.3996,  -6.5025],\n",
       "         [-15.5996,  -3.2054,  -2.2044,  ..., -15.5657, -15.3228, -12.5837],\n",
       "         [-17.5993,  -0.8993,   1.6083,  ..., -17.9851, -17.7867, -13.4420],\n",
       "         [-16.7966,  -3.6326,  -4.0517,  ..., -17.2331, -16.9205, -13.8225],\n",
       "         [-18.1991,   1.8396,   3.7016,  ..., -18.3652, -17.6390,  -7.9669],\n",
       "         [-17.6584,  -4.5549,  -2.7929,  ..., -17.4542, -17.2802, -14.5661]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output= model(trg)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32770,   646,  8027,    14, 13563,   465,  4488,   199,   646,  8027,\n",
       "            14, 13563,   465,  4488,   199,   646,  2680,   465,   980,   199,\n",
       "           504,  8027,    14, 13563,   465,  4488,   199,   504,  6357,    14,\n",
       "          7120,   492,  4488,   199,   504,  6357,    14,  7120,   492,  9229,\n",
       "           199,   504,  6357,    14,  7120,   492,  6904,   199,   504,  6357,\n",
       "            14,  1238,   492,  6904,   199,   504,  6357,    14, 12281,   492,\n",
       "          1852,    63,  7120,    12,  1852,    63, 21893,   199,   504,  6357,\n",
       "            14,  6676,    63,  1238,   492, 27903,   199,   504,  6357,    14,\n",
       "          1208]], device='cuda:0')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.detach()\n",
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.ticker import=matplotlib.pyplot as plt.subplot\n",
      "from sklearn.linear import matplotlib.pyplot as plt\n",
      "from sklearn.semilogx = plt.rcParams['xtick.rcParams']['text.rcParams']['usetex']\n",
      "\n",
      "from sklearn.rcParams['figure.grid_size'] = 'xtick.size'\n",
      "\n",
      "\n",
      "plt.figure.rcParams['font.size'] = plt.rcParams['font_size']\n",
      "plt.rcParams['font.font.rc\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def suggestor(prompt,model,tokenizer,max_lenght=130):\n",
    "    tokenized =tokenizer(prompt)[\"input_ids\"]\n",
    "    trg =torch.LongTensor([tokenizer.bos_token_id]+tokenized).reshape(1,-1)\n",
    "    trg=trg.to(device)\n",
    "    with torch.no_grad():\n",
    "        for i in range(max_lenght):\n",
    "            output= model.greedy_decode(trg)\n",
    "            trg = torch.cat((trg, output[-1].reshape(1,-1)), dim=1)\n",
    "\n",
    "            if output[-1] == tokenizer.eos_token_id:\n",
    "                break\n",
    "    result = tokenizer.decode(trg.squeeze(0),skip_special_tokens=True)\n",
    "    trg.detach()\n",
    "\n",
    "    return result\n",
    "\n",
    "prompt = \"import numpy\"\n",
    "print(suggestor(prompt,model,tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([21])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg.squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32770,   646,  8027,    14, 13563,   465,  4488,   199,   646,  8027,\n",
       "            14, 13563,   465,  4488,   199,   646,  2680,   465,   980,   199,\n",
       "           504]], device='cuda:0')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32770,   646,  8027,    14, 13563,   465]], device='cuda:0')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4488, device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4488]], device='cuda:0')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[-1].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((trg, output[-1].reshape(1,-1)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[32770,   646,  8027,    14, 13563,   465,  4488]], device='cuda:0')"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text + tokenizer.decode(output[-1],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction= model(trg)\n",
    "prediction = prediction.squeeze(0)\n",
    "prediction = prediction # not include first one? \n",
    "prediction = prediction.argmax(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import matplotlib.pyplot as plt'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trg_text + tokenizer.decode(output[-1],skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12b51c3a15c6d04bbe25e0ed0a8589f4bf8f73b3e40dc1f9d202d81fcb7450ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
